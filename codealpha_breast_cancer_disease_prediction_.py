# -*- coding: utf-8 -*-
"""CodeAlpha_Breast Cancer Disease Prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fFrxK7o23CkcY2XqrXtpAmfV_7huN4Kj

**TASK 4 - BREAST CANCER DISEASE PREDICTION**

**Importation of python libraries & dataset**
"""

import pandas as pd
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.inspection import permutation_importance

"""**Load Breast Cancer Dataset**"""

data = load_breast_cancer()

# Convert to Dataframe
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

"""**Data Inspection**"""

df.head()

df.tail()

df.describe()

df.info()

"""**Split Data**"""

# Features & Target
X = df.drop('target', axis = 1)
y = df['target']

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""**Scale Features**"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""**Model 1: Logistic Regression**"""

lr = LogisticRegression(max_iter=500)
lr.fit(X_train, y_train)

"""**Model 2: Support Vector Machine**"""

svm = SVC(kernel = "rbf", probability = True)
svm.fit(X_train, y_train)

"""**Model 3: Random Forest Classifier**"""

rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

"""**Model 4: XGBoost Classifier**"""

xgb = XGBClassifier(eval_metric="logloss")
xgb.fit(X_train, y_train)

"""**Evaluation of all models**"""

models = {
    "Logistic Regression": lr,
    "Support Vector Machine": svm,
    "Random Forest Classifier": rf,
    "XGBoost Classifier": xgb
}

for name, model in models.items():
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    print(f"\n {name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, preds))

"""**Feature Importance for Logistic Regression**"""

lr_importance = abs(lr.coef_[0])
feature_names = X.columns

lr_series = pd.Series(lr_importance, index=feature_names).sort_values(ascending=False)
lr_series

"""**Plot for lr Feature Importance**"""

lr_series.nlargest(15).plot(kind="barh", figsize=(8,6))
plt.title("Logistic Regression Feature Importance (Coefficients)")
plt.show()

"""**Feature Importance for Random Forest**

---


"""

importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
names = X.columns[indices]

plt.figure(figsize=(10, 8))
sns.barplot(x=importances[indices], y=names)
plt.title("Random Forest Feature Importance")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

"""**Feature Importance for XGBoost**"""

xgb_importance = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)
xgb_importance

"""**Feature Importance Support Vector Machine**"""

svm_perm = permutation_importance(svm, X_test, y_test, n_repeats=10)

svm_importance = pd.Series(svm_perm.importances_mean, index=X.columns).sort_values(ascending=False)
svm_importance

"""**Plot for SVM Feature Importance**"""

svm_importance.nlargest(15).plot(kind="barh", figsize=(8,6))
plt.title("SVM Feature Importance (Permutation Importance)")
plt.show()